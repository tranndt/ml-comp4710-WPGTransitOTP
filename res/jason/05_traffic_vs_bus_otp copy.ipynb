{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import myutils as u\n",
    "import math\n",
    "import datetime\n",
    "import warnings\n",
    "import pandas.errors\n",
    "warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TC_SITES = u.import_data(\"SITES\")\n",
    "ALL_TC = u.import_data(\"TRAFFIC_COUNTS\")\n",
    "ALL_OTP = u.import_data(\"ON_TIME\")\n",
    "ALL_STOPS = u.import_data(\"STOPS\")\n",
    "ALL_CONSTR = u.import_data(\"LANE_CLOSURE\")\n",
    "ALL_ROADS = u.import_data(\"ROAD_NETWORK\")\n",
    "\n",
    "# Consts\n",
    "MIN = pd.to_timedelta(\"1 min\")\n",
    "DAY = pd.to_timedelta(\"1 day\")\n",
    "SITES_NO = {'McPhillips': 0,'Henderson': 1,'Pembina': 2,'Inkster': 3,'Nichol': 4,'Lagimodiere': 5,'Disraeli': 6,'Marion': 7} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stops_distances(tc_site, distance=500,key=None):\n",
    "    TC_SITE = ALL_TC_SITES[ALL_TC_SITES[\"Street\"] == tc_site]\n",
    "    site_coords = TC_SITE[[\"Lat\",\"Long\"]].values[0]\n",
    "    stop_coords = ALL_STOPS[[\"Lat\",\"Long\"]].values\n",
    "    distances = u.distance_within(site_coords,stop_coords,distance,key=key)\n",
    "    return distances \n",
    "\n",
    "def get_stops_nearby(tc_site, distance=500):\n",
    "    stops_index = get_stops_distances(tc_site, distance, \"index\")\n",
    "    return ALL_STOPS.iloc[stops_index]\n",
    "\n",
    "def get_traffic_counts(tc_site,date,freq=None):\n",
    "    # Obtain the traffic count information\n",
    "    TC_SITE = ALL_TC_SITES[ALL_TC_SITES[\"Street\"] == tc_site]\n",
    "    TC = ALL_TC[(ALL_TC[\"Timestamp\"]>date) & (ALL_TC[\"Timestamp\"]<= date+1*DAY) & (ALL_TC[\"Street\"]==TC_SITE[\"Street\"].item())]\n",
    "    TC.loc[:,\"Time Interval\"] = [u.fmt_timestamp(i) for i in TC[\"Timestamp\"]]\n",
    "\n",
    "    if freq != None:\n",
    "    # Select the frequency with which the data is aggregated\n",
    "        time_range = date + pd.timedelta_range(start=\"0:00:00\",end=\"24:00:00\",freq=freq)\n",
    "        AGGR_TC = pd.DataFrame()\n",
    "        cols = [\"Northbound\",\"Southbound\",\"Eastbound\",\"Westbound\",\"Total\"]\n",
    "        for i in range(len(time_range)-1):\n",
    "            lower_lim = time_range[i]\n",
    "            upper_lim = time_range[i+1]\n",
    "            res = TC[TC[\"Timestamp\"] == upper_lim]\n",
    "            res.loc[:,cols] = TC.loc[(TC[\"Timestamp\"] <= upper_lim) & (TC[\"Timestamp\"] > lower_lim),cols].sum(axis=0).values\n",
    "            AGGR_TC = pd.concat([AGGR_TC,res])\n",
    "        TC = AGGR_TC\n",
    "    return TC.sort_values(\"Timestamp\")\n",
    "\n",
    "def get_otp(start,end):\n",
    "    return ALL_OTP[(ALL_OTP[\"Scheduled Time\"] <= end) & (ALL_OTP[\"Scheduled Time\"] > start)]\n",
    "\n",
    "def prepare_data(tc_site,date,distance=500,freq=None):\n",
    "    AFF_STOPS = get_stops_nearby(tc_site, distance)\n",
    "    distances = get_stops_distances(tc_site, distance,key=\"distance\")\n",
    "    TC = get_traffic_counts(tc_site,date,freq)\n",
    "    OTP = get_otp(date, date+1*DAY)\n",
    "    DF = pd.DataFrame()\n",
    "    for timestamp in TC[\"Timestamp\"]:\n",
    "        TC_i = TC[TC[\"Timestamp\"] == timestamp]\n",
    "        df1 = AFF_STOPS.loc[:,[\"Stop Number\"]]\n",
    "        df1.loc[:,\"Site\"] = tc_site\n",
    "        df1.loc[:,\"Distance\"] = distances\n",
    "        df1.loc[:,\"Same Street\"] = (AFF_STOPS[\"Street\"] == TC_i[\"Street\"].item()).replace({True:1,False:0})\n",
    "        # Directional & Total traffic count\n",
    "        df1.loc[(AFF_STOPS[\"Street\"] != tc_site),\"Directional\"] = 0\n",
    "        for direction in [\"Northbound\",\"Southbound\",\"Eastbound\",\"Westbound\"]:\n",
    "            df1.loc[(AFF_STOPS[\"Street\"] == tc_site) & (AFF_STOPS[\"Direction\"] == direction),\"Directional\"] = TC_i[direction].item()\n",
    "        df1.loc[:,\"Total\"] = TC_i[\"Total\"].item()\n",
    "        # \n",
    "        df1.loc[:,[\"Arrivals\",\"Average OTP\"]] = [(len(OTP.loc[OTP[\"Stop Number\"]==stop_no,\"Deviation\"].values),OTP.loc[OTP[\"Stop Number\"]==stop_no,\"Deviation\"].values.mean()) \n",
    "                                                                for stop_no in AFF_STOPS[\"Stop Number\"]]\n",
    "        df1.loc[:,\"Time interval\"] = u.fmt_timestamp(timestamp)\n",
    "        df1.loc[:,\"Date\"] = TC_i[\"Timestamp\"].item().date()\n",
    "        DF = pd.concat([DF,df1])\n",
    "    return DF\n",
    "\n",
    "date = pd.to_datetime(\"2021-08-23\")\n",
    "tc_site = \"McPhillips\"\n",
    "distance=500\n",
    "freq = \"2h\"\n",
    "\n",
    "AFF_STOPS = get_stops_nearby(tc_site, distance)\n",
    "TC = get_traffic_counts(tc_site,date,freq)\n",
    "prepare_data(tc_site,date,distance,freq)\n",
    "# AFF_STOPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Irrelevant Bus Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_STOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TC_SITES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_coords = ALL_STOPS[[\"Lat\",\"Long\"]].values\n",
    "all_stops = set(ALL_STOPS.index)\n",
    "valid_stops = set()\n",
    "for org in ALL_TC_SITES[[\"Lat\",\"Long\"]].values:\n",
    "    valid_stop_i = set(u.distance_within(org,stop_coords,d=5000,key=\"index\"))\n",
    "    valid_stops |= valid_stop_i\n",
    "invalid_stops = all_stops - valid_stops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_STOPS.loc[pd.Index(invalid_stops)]\n",
    "stop = ALL_STOPS.loc[pd.Index(invalid_stops),[\"Lat\",\"Long\"]].values[1]\n",
    "print(ALL_STOPS.loc[pd.Index(invalid_stops)].values[1])\n",
    "tc_stations = ALL_TC_SITES[[\"Lat\",\"Long\"]].values\n",
    "u.distance_within(stop,tc_stations,d=1e9,key=\"distance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_STOPS = ALL_STOPS.loc[pd.Index(valid_stops)]\n",
    "VALID_STOPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Weights\n",
    "\n",
    "## Data shapes:\n",
    "1. stop:\n",
    "    (Lat, Long, Stop number)\n",
    "2. times:\n",
    "    ['2021-08-01 20:00:00', '2021-08-01 20:15:00']\n",
    "3. traffic counts:\n",
    "    (Lat, Long, Total count, Site name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAggregateWeight(stop: tuple, times: list) -> float:\n",
    "    \"\"\"\n",
    "    Calculate aggregate weight of a bus stop with the traffic count stations at given times\n",
    "\n",
    "    Arguments:\n",
    "        - stop: a geo coordinate in tuple\n",
    "        - times: a list of string contaning date and time to select from\n",
    "\n",
    "    Returns:\n",
    "        aggregate weight of a bus stop with the traffic count stations at given times\n",
    "    \"\"\"\n",
    "    get_traffic_counts = lambda time: ALL_TC.loc[ALL_TC[\"Timestamp\"] == time][[\"Lat\", \"Long\", \"Total\", \"Site\"]].sort_values(by=\"Lat\")\n",
    "    \n",
    "    traffic_counts = np.zeros(8, dtype=np.int64)\n",
    "    for time in times:\n",
    "        tc_stations = get_traffic_counts(time)\n",
    "        traffic_counts = np.add(tc_stations.Total.tolist(), traffic_counts)\n",
    "\n",
    "    distances = u.distance_within(stop[:2], tc_stations.values, d=1e9, key=\"distance\")\n",
    "    coefficients = [1/dist for dist in distances]\n",
    "    \n",
    "    return np.dot(coefficients, traffic_counts.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerateTimes(start: str, end: str, num_interval: int):\n",
    "    \"\"\"\n",
    "    Enumerate time intervals with given start and end time, and the number of invertal of 15 mins.\n",
    "\n",
    "    Arguments:\n",
    "        - start: a string in the format defined in DATE_TIME_FORMAT\n",
    "        - end: a string in the format defined in DATE_TIME_FORMAT\n",
    "        - num_interval: number of interval of 15 mins. \n",
    "\n",
    "    Returns:\n",
    "        A 2-layer nested list contaning enumerated time.\n",
    "        The outer layer gives the a list of datetime string that is separated by a 15 minutes time interval.\n",
    "\n",
    "    Example:\n",
    "        `enumerateTimes(\"2021-08-01 02:00:00\", \"2021-08-01 04:00:00\", 2)` gives the following result:  \n",
    "        \n",
    "        \n",
    "        ```\n",
    "        [['2021-08-01 02:00:00', '2021-08-01 02:15:00'],    \n",
    "        ['2021-08-01 02:30:00', '2021-08-01 02:45:00'],    \n",
    "        ['2021-08-01 03:00:00', '2021-08-01 03:15:00'],   \n",
    "        ['2021-08-01 03:30:00', '2021-08-01 03:45:00']]  \n",
    "        ```\n",
    "    \"\"\"\n",
    "    DATE_TIME_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n",
    "    str2time = lambda str: datetime.datetime.strptime(str, DATE_TIME_FORMAT)\n",
    "    time2str = lambda time: time.strftime(DATE_TIME_FORMAT)\n",
    "\n",
    "    startTime = str2time(start)\n",
    "    endTime = str2time(end)\n",
    "    interval = datetime.timedelta(minutes=15)\n",
    "\n",
    "    ret = []\n",
    "    currentTime = startTime\n",
    "    while (currentTime < endTime):\n",
    "        chunk = []\n",
    "        for i in range(0, num_interval):\n",
    "            chunk.append(time2str(currentTime))\n",
    "            currentTime = currentTime + interval\n",
    "        ret.append(chunk)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in enumerateTimes(\"2021-08-01 20:00:00\", \"2021-08-01 21:00:00\", 2):\n",
    "    for stop in VALID_STOPS[[\"Lat\",\"Long\", \"Stop Number\"]].values:\n",
    "        hook_this_to_somewhere = calculateAggregateWeight(stop, time) # TODO\n",
    "        print(f\"for time == {time}, stop == {stop[2]}, aggregate weight is {hook_this_to_somewhere}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 2.7.18 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
